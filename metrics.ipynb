{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065dfcb0-e15c-48c6-81f4-0ad66addefb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  city_id  total_trips  monthly_revenue  total_distance  avg_passenger_rating  \\\n",
      "0    AP01        28366          8018282          639765              8.434342   \n",
      "1    CH01        38981         11058401          916783              7.973127   \n",
      "2    GJ01        54843          6431599          603122              6.420498   \n",
      "3    GJ02        32026          3797200          368867              6.616081   \n",
      "4    KA01        16238          4054745          267877              8.704889   \n",
      "\n",
      "   avg_driver_rating  new_trips  repeated_trips  avg_trip_distance  \\\n",
      "0           8.987120      12747           15619          22.554778   \n",
      "1           7.722465      18908           20073          23.523374   \n",
      "2           6.589763      11626           43217          10.995752   \n",
      "3           6.648147      10127           21899          11.519337   \n",
      "4           8.978083      11681            4557          16.493180   \n",
      "\n",
      "   max_trip_distance  min_trip_distance  total_passengers  new_passengers  \\\n",
      "0                 35                 10             17855           12747   \n",
      "1                 35                 12             23978           18908   \n",
      "2                 17                  5             20264           11626   \n",
      "3                 18                  5             14473           10127   \n",
      "4                 25                  8             13158           11681   \n",
      "\n",
      "   repeat_passengers  repeat_passenger_rate  trip_target_achievement  \n",
      "0               5108              28.811272                99.789630  \n",
      "1               5070              21.750782               100.040079  \n",
      "2               8638              42.963123                96.348333  \n",
      "3               4346              30.793795                85.451496  \n",
      "4               1477              11.208195               121.230000  \n",
      "  month_name  total_trips  monthly_revenue  total_distance  \\\n",
      "0      April        71335         17695759         1344952   \n",
      "1   February        75379         19859356         1467823   \n",
      "2    January        70462         18454142         1377639   \n",
      "3       June        62505         15357284         1167950   \n",
      "4      March        73679         18836382         1411113   \n",
      "\n",
      "   avg_passenger_rating  avg_driver_rating  new_trips  repeated_trips  \\\n",
      "0              7.700859           7.873313      26620           44715   \n",
      "1              7.823407           7.900287      36201           39178   \n",
      "2              7.871626           7.915905      36329           34133   \n",
      "3              7.674746           7.864844      22852           39653   \n",
      "4              7.749193           7.889318      30814           42865   \n",
      "\n",
      "   avg_trip_distance  max_trip_distance  min_trip_distance  total_passengers  \\\n",
      "0          18.335566                 45                  5             37633   \n",
      "1          18.299389                 45                  5             45724   \n",
      "2          18.328552                 45                  5             44672   \n",
      "3          18.346249                 45                  5             32533   \n",
      "4          18.276917                 45                  5             41398   \n",
      "\n",
      "   new_passengers  repeat_passengers  repeat_passenger_rate  \\\n",
      "0           26620              11013              29.954389   \n",
      "1           36201               9523              21.815805   \n",
      "2           36329               8343              19.718611   \n",
      "3           22852               9681              30.908307   \n",
      "4           30814              10584              25.980854   \n",
      "\n",
      "   trip_target_achievement  \n",
      "0               101.018952  \n",
      "1               105.096503  \n",
      "2                99.047482  \n",
      "3                90.309974  \n",
      "4               105.092851  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets (Assuming CSV files, you can modify paths accordingly)\n",
    "trips_df = pd.read_csv(r\"C:\\Users\\anshi\\OneDrive\\Desktop\\Data analyst\\Resume project challange_13\\resources\\datasets\\csv_files\\trips_db\\fact_trips.csv\")\n",
    "passenger_summary_df = pd.read_csv(r\"C:\\Users\\anshi\\OneDrive\\Desktop\\Data analyst\\Resume project challange_13\\resources\\datasets\\csv_files\\trips_db\\fact_passenger_summary.csv\")\n",
    "dim_date_df = pd.read_csv(r\"C:\\Users\\anshi\\OneDrive\\Desktop\\Data analyst\\Resume project challange_13\\resources\\datasets\\csv_files\\trips_db\\dim_date.csv\")\n",
    "city_target_passenger_rating = pd.read_csv(r\"C:\\Users\\anshi\\OneDrive\\Desktop\\Data analyst\\Resume project challange_13\\resources\\datasets\\csv_files\\targets_db\\city_target_passenger_rating.csv\")\n",
    "target_trips_df = pd.read_csv(r\"C:\\Users\\anshi\\OneDrive\\Desktop\\Data analyst\\Resume project challange_13\\resources\\datasets\\csv_files\\targets_db\\monthly_target_trips.csv\")\n",
    "monthly_target_new_passenger = pd.read_csv(r\"C:\\Users\\anshi\\OneDrive\\Desktop\\Data analyst\\Resume project challange_13\\resources\\datasets\\csv_files\\targets_db\\monthly_target_new_passengers.csv\")\n",
    "dim_city_df = pd.read_csv(r\"C:\\Users\\anshi\\OneDrive\\Desktop\\Data analyst\\Resume project challange_13\\resources\\datasets\\csv_files\\trips_db\\dim_city.csv\")\n",
    "dim_repeat_trip_distribution_df = pd.read_csv(r\"C:\\Users\\anshi\\OneDrive\\Desktop\\Data analyst\\Resume project challange_13\\resources\\datasets\\csv_files\\trips_db\\dim_repeat_trip_distribution.csv\")\n",
    "\n",
    "# Merging data to include the month name in the analysis\n",
    "df = pd.merge(trips_df, dim_date_df[['date', 'month_name']], how='left', on='date')\n",
    "\n",
    "# Metric 1: Total Trips\n",
    "total_trips = df.groupby(['city_id', 'month_name']).agg(\n",
    "    total_trips=('trip_id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Metric 2: Total Revenue (Fare)\n",
    "total_revenue = df.groupby(['city_id', 'month_name']).agg(\n",
    "    monthly_revenue=('fare_amount', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Metric 3: Total Distance Travelled (Note: Use exact column name for distance travelled)\n",
    "total_distance = df.groupby(['city_id', 'month_name']).agg(\n",
    "    total_distance=('distance_travelled(km)', 'sum')  # Correct column name with the parentheses\n",
    ").reset_index()\n",
    "\n",
    "# Metric 4: Average Passenger Rating\n",
    "avg_passenger_rating = df.groupby(['city_id', 'month_name']).agg(\n",
    "    avg_passenger_rating=('passenger_rating', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Metric 5: Average Driver Rating\n",
    "avg_driver_rating = df.groupby(['city_id', 'month_name']).agg(\n",
    "    avg_driver_rating=('driver_rating', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Metric 6: New Trips (Count of trips by new passengers)\n",
    "new_trips = df[df['passenger_type'] == 'new'].groupby(['city_id', 'month_name']).agg(\n",
    "    new_trips=('trip_id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Metric 7: Repeated Trips (Count of trips by repeated passengers)\n",
    "repeated_trips = df[df['passenger_type'] == 'repeated'].groupby(['city_id', 'month_name']).agg(\n",
    "    repeated_trips=('trip_id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Metric 8: Average Trip Distance\n",
    "avg_trip_distance = df.groupby(['city_id', 'month_name']).agg(\n",
    "    avg_trip_distance=('distance_travelled(km)', 'mean')  # Correct column name with parentheses\n",
    ").reset_index()\n",
    "\n",
    "# Metric 9: Maximum and Minimum Trip Distance\n",
    "max_min_distance = df.groupby(['city_id', 'month_name']).agg(\n",
    "    max_trip_distance=('distance_travelled(km)', 'max'),\n",
    "    min_trip_distance=('distance_travelled(km)', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Metric 10: Total Passengers, New Passengers, Repeat Passengers\n",
    "passenger_summary_df['month_name'] = pd.to_datetime(passenger_summary_df['month'], format='%Y-%m-%d').dt.strftime('%B')\n",
    "passenger_summary = passenger_summary_df.groupby(['city_id', 'month_name']).agg(\n",
    "    total_passengers=('total_passengers', 'sum'),\n",
    "    new_passengers=('new_passengers', 'sum'),\n",
    "    repeat_passengers=('repeat_passengers', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Merge all the metrics\n",
    "final_df = total_trips.merge(total_revenue, on=['city_id', 'month_name'])\n",
    "final_df = final_df.merge(total_distance, on=['city_id', 'month_name'])\n",
    "final_df = final_df.merge(avg_passenger_rating, on=['city_id', 'month_name'])\n",
    "final_df = final_df.merge(avg_driver_rating, on=['city_id', 'month_name'])\n",
    "final_df = final_df.merge(new_trips, on=['city_id', 'month_name'])\n",
    "final_df = final_df.merge(repeated_trips, on=['city_id', 'month_name'])\n",
    "final_df = final_df.merge(avg_trip_distance, on=['city_id', 'month_name'])\n",
    "final_df = final_df.merge(max_min_distance, on=['city_id', 'month_name'])\n",
    "final_df = final_df.merge(passenger_summary, on=['city_id', 'month_name'])\n",
    "\n",
    "# Add the monthly trip target data\n",
    "# Ensure correct date format for `target_trips_df['month']`\n",
    "# Try to handle both formats: 'YYYY-MM-DD' or 'DD-MM-YYYY'\n",
    "target_trips_df['month_name'] = pd.to_datetime(target_trips_df['month'], errors='coerce', dayfirst=True).dt.strftime('%B')\n",
    "final_df = final_df.merge(target_trips_df[['city_id', 'month_name', 'total_target_trips']], on=['city_id', 'month_name'], how='left')\n",
    "\n",
    "# Metric 11: Trip Target Achievement (percentage)\n",
    "final_df['trip_target_achievement'] = final_df['total_trips'] * 100.0 / final_df['total_target_trips']\n",
    "\n",
    "# Metric 12: Repeat Passenger Rate\n",
    "final_df['repeat_passenger_rate'] = final_df['repeat_passengers'] * 100.0 / final_df['total_passengers']\n",
    "\n",
    "# File 1: Grouped by city_id\n",
    "final_df_city = final_df.groupby('city_id').agg(\n",
    "    total_trips=('total_trips', 'sum'),\n",
    "    monthly_revenue=('monthly_revenue', 'sum'),\n",
    "    total_distance=('total_distance', 'sum'),\n",
    "    avg_passenger_rating=('avg_passenger_rating', 'mean'),\n",
    "    avg_driver_rating=('avg_driver_rating', 'mean'),\n",
    "    new_trips=('new_trips', 'sum'),\n",
    "    repeated_trips=('repeated_trips', 'sum'),\n",
    "    avg_trip_distance=('avg_trip_distance', 'mean'),\n",
    "    max_trip_distance=('max_trip_distance', 'max'),\n",
    "    min_trip_distance=('min_trip_distance', 'min'),\n",
    "    total_passengers=('total_passengers', 'sum'),\n",
    "    new_passengers=('new_passengers', 'sum'),\n",
    "    repeat_passengers=('repeat_passengers', 'sum'),\n",
    "    repeat_passenger_rate=('repeat_passenger_rate', 'mean'),\n",
    "    trip_target_achievement=('trip_target_achievement', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# File 2: Grouped by month_name\n",
    "final_df_month = final_df.groupby('month_name').agg(\n",
    "    total_trips=('total_trips', 'sum'),\n",
    "    monthly_revenue=('monthly_revenue', 'sum'),\n",
    "    total_distance=('total_distance', 'sum'),\n",
    "    avg_passenger_rating=('avg_passenger_rating', 'mean'),\n",
    "    avg_driver_rating=('avg_driver_rating', 'mean'),\n",
    "    new_trips=('new_trips', 'sum'),\n",
    "    repeated_trips=('repeated_trips', 'sum'),\n",
    "    avg_trip_distance=('avg_trip_distance', 'mean'),\n",
    "    max_trip_distance=('max_trip_distance', 'max'),\n",
    "    min_trip_distance=('min_trip_distance', 'min'),\n",
    "    total_passengers=('total_passengers', 'sum'),\n",
    "    new_passengers=('new_passengers', 'sum'),\n",
    "    repeat_passengers=('repeat_passengers', 'sum'),\n",
    "    repeat_passenger_rate=('repeat_passenger_rate', 'mean'),\n",
    "    trip_target_achievement=('trip_target_achievement', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Save the results to CSV\n",
    "final_df_city.to_csv('goodcabs_analysis_by_city.csv', index=False)\n",
    "final_df_month.to_csv('goodcabs_analysis_by_month.csv', index=False)\n",
    "\n",
    "# Optionally, print the first few rows of the files\n",
    "print(final_df_city.head())\n",
    "print(final_df_month.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9477d707-d9a4-472b-94e2-d7df9255a85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis completed and results saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets with date parsing\n",
    "trips_df = pd.read_csv(\n",
    "    r\"C:\\Users\\anshi\\OneDrive\\Desktop\\Data analyst\\Resume project challange_13\\resources\\datasets\\csv_files\\trips_db\\fact_trips.csv\",\n",
    "    parse_dates=[\"date\"], dayfirst=True\n",
    ")\n",
    "dim_date_df = pd.read_csv(\n",
    "    r\"C:\\Users\\anshi\\OneDrive\\Desktop\\Data analyst\\Resume project challange_13\\resources\\datasets\\csv_files\\trips_db\\dim_date.csv\",\n",
    "    parse_dates=[\"date\", \"start_of_month\"], dayfirst=True\n",
    ")\n",
    "dim_repeat_trip_distribution_df = pd.read_csv(\n",
    "    r\"C:\\Users\\anshi\\OneDrive\\Desktop\\Data analyst\\Resume project challange_13\\resources\\datasets\\csv_files\\trips_db\\dim_repeat_trip_distribution.csv\",\n",
    "    parse_dates=[\"month\"], dayfirst=True\n",
    ")\n",
    "\n",
    "# Clean and preprocess the datasets\n",
    "# Remove \"-Trips\" suffix and convert `trip_count` to numeric\n",
    "dim_repeat_trip_distribution_df['trip_count'] = dim_repeat_trip_distribution_df['trip_count'].str.replace('-Trips', '').astype(int)\n",
    "\n",
    "# Ensure all numeric columns in fact_trips are properly formatted\n",
    "trips_df['distance_travelled(km)'] = pd.to_numeric(trips_df['distance_travelled(km)'], errors='coerce')\n",
    "trips_df['fare_amount'] = pd.to_numeric(trips_df['fare_amount'], errors='coerce')\n",
    "\n",
    "# Explicitly ensure date columns are in datetime format\n",
    "trips_df['date'] = pd.to_datetime(trips_df['date'], dayfirst=True)\n",
    "dim_date_df['date'] = pd.to_datetime(dim_date_df['date'], dayfirst=True)\n",
    "\n",
    "# Primary Analysis Functions\n",
    "\n",
    "# 1. Top and Bottom Performing Cities by Total Trips\n",
    "def top_bottom_cities(trips_df):\n",
    "    city_summary = trips_df.groupby('city_id').agg(\n",
    "        total_trips=('trip_id', 'count')\n",
    "    ).reset_index()\n",
    "    city_summary = city_summary.sort_values(by='total_trips', ascending=False)\n",
    "    top_cities = city_summary.head(3)\n",
    "    bottom_cities = city_summary.tail(3)\n",
    "    return top_cities, bottom_cities\n",
    "\n",
    "# 2. Average Fare per Trip by City\n",
    "def avg_fare_per_trip(trips_df):\n",
    "    avg_fare = trips_df.groupby('city_id').agg(\n",
    "        total_fare=('fare_amount', 'sum'),\n",
    "        total_trips=('trip_id', 'count')\n",
    "    ).reset_index()\n",
    "    avg_fare['avg_fare_per_trip'] = avg_fare['total_fare'] / avg_fare['total_trips']\n",
    "    return avg_fare[['city_id', 'avg_fare_per_trip']]\n",
    "\n",
    "# 3. Peak and Low Demand Months by City\n",
    "def peak_low_demand(trips_df, dim_date_df):\n",
    "    trips_df = pd.merge(trips_df, dim_date_df[['date', 'month_name']], on='date', how='left')\n",
    "    monthly_summary = trips_df.groupby(['city_id', 'month_name']).agg(\n",
    "        total_trips=('trip_id', 'count')\n",
    "    ).reset_index()\n",
    "    peak_months = monthly_summary.loc[monthly_summary.groupby('city_id')['total_trips'].idxmax()]\n",
    "    low_months = monthly_summary.loc[monthly_summary.groupby('city_id')['total_trips'].idxmin()]\n",
    "    return peak_months, low_months\n",
    "\n",
    "# 4. Weekend vs Weekday Trip Demand\n",
    "def weekend_vs_weekday_analysis(trips_df, dim_date_df):\n",
    "    trips_df = pd.merge(trips_df, dim_date_df[['date', 'day_type']], on='date', how='left')\n",
    "    weekday_weekend = trips_df.groupby(['city_id', 'day_type']).agg(\n",
    "        total_trips=('trip_id', 'count')\n",
    "    ).reset_index()\n",
    "    return weekday_weekend\n",
    "\n",
    "# 5. Repeat Passenger Frequency and Contribution\n",
    "def repeat_passenger_analysis(dim_repeat_trip_distribution_df):\n",
    "    repeat_freq = dim_repeat_trip_distribution_df.groupby(['city_id']).agg(\n",
    "        total_repeat_passengers=('repeat_passenger_count', 'sum'),\n",
    "        total_trips=('trip_count', 'sum')\n",
    "    ).reset_index()\n",
    "    repeat_freq['repeat_passenger_rate'] = (\n",
    "        repeat_freq['total_repeat_passengers'] * 100.0 / repeat_freq['total_trips']\n",
    "    )\n",
    "    return repeat_freq\n",
    "\n",
    "# Run the analysis\n",
    "analysis_results = {\n",
    "    \"top_bottom_cities\": top_bottom_cities(trips_df),\n",
    "    \"avg_fare_per_trip\": avg_fare_per_trip(trips_df),\n",
    "    \"peak_low_demand\": peak_low_demand(trips_df, dim_date_df),\n",
    "    \"weekend_vs_weekday\": weekend_vs_weekday_analysis(trips_df, dim_date_df),\n",
    "    \"repeat_passenger_analysis\": repeat_passenger_analysis(dim_repeat_trip_distribution_df)\n",
    "}\n",
    "\n",
    "# Save results to CSV\n",
    "for key, result in analysis_results.items():\n",
    "    if isinstance(result, tuple):  # Handle metrics with high/low segmentation\n",
    "        result[0].to_csv(f\"{key}_high.csv\", index=False)\n",
    "        result[1].to_csv(f\"{key}_low.csv\", index=False)\n",
    "    else:\n",
    "        result.to_csv(f\"{key}.csv\", index=False)\n",
    "\n",
    "print(\"Analysis completed and results saved.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c6aeff-65c5-4b3a-ad30-d3695f4d8652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "top_bottom_cities - High:\n",
      "   city_id  total_trips\n",
      "7    RJ01        76888\n",
      "9    UP01        64299\n",
      "2    GJ01        54843\n",
      "\n",
      "top_bottom_cities - Low:\n",
      "   city_id  total_trips\n",
      "0    AP01        28366\n",
      "8    TN01        21104\n",
      "4    KA01        16238\n",
      "\n",
      "avg_fare_per_trip:\n",
      "   city_id  avg_fare_per_trip\n",
      "0    AP01         282.672284\n",
      "1    CH01         283.686950\n",
      "2    GJ01         117.272925\n",
      "3    GJ02         118.566165\n",
      "4    KA01         249.707168\n",
      "5    KL01         335.245079\n",
      "6    MP01         179.838609\n",
      "7    RJ01         483.918128\n",
      "8    TN01         166.982183\n",
      "9    UP01         147.180376\n",
      "\n",
      "peak_low_demand - High:\n",
      "    city_id month_name  total_trips\n",
      "0     AP01      April         1033\n",
      "6     CH01      April         1470\n",
      "12    GJ01      April         1903\n",
      "21    GJ02       June         1152\n",
      "27    KA01       June          612\n",
      "30    KL01      April         1947\n",
      "36    MP01      April         1603\n",
      "46    RJ01      March         3007\n",
      "51    TN01       June          762\n",
      "57    UP01       June         2247\n",
      "\n",
      "peak_low_demand - Low:\n",
      "    city_id month_name  total_trips\n",
      "2     AP01    January          769\n",
      "8     CH01    January         1031\n",
      "14    GJ01    January         1694\n",
      "20    GJ02    January          984\n",
      "26    KA01    January          395\n",
      "32    KL01    January         1270\n",
      "38    MP01    January         1122\n",
      "44    RJ01    January         1868\n",
      "50    TN01    January          591\n",
      "55    UP01   February         2016\n",
      "\n",
      "weekend_vs_weekday:\n",
      "    city_id day_type  total_trips\n",
      "0     AP01  Weekday         3572\n",
      "1     AP01  Weekend         2045\n",
      "2     CH01  Weekday         4723\n",
      "3     CH01  Weekend         2836\n",
      "4     GJ01  Weekday         7656\n",
      "5     GJ01  Weekend         3136\n",
      "6     GJ02  Weekday         4337\n",
      "7     GJ02  Weekend         2019\n",
      "8     KA01  Weekday         1855\n",
      "9     KA01  Weekend         1311\n",
      "10    KL01  Weekday         6138\n",
      "11    KL01  Weekend         3773\n",
      "12    MP01  Weekday         5318\n",
      "13    MP01  Weekend         3017\n",
      "14    RJ01  Weekday         8953\n",
      "15    RJ01  Weekend         6243\n",
      "16    TN01  Weekday         2766\n",
      "17    TN01  Weekend         1305\n",
      "18    UP01  Weekday         9436\n",
      "19    UP01  Weekend         3304\n",
      "\n",
      "repeat_passenger_analysis:\n",
      "   city_id  total_repeat_passengers  total_trips  repeat_passenger_rate\n",
      "0    AP01                     5108          324            1576.543210\n",
      "1    CH01                     5070          324            1564.814815\n",
      "2    GJ01                     8638          324            2666.049383\n",
      "3    GJ02                     4346          324            1341.358025\n",
      "4    KA01                     1477          324             455.864198\n",
      "5    KL01                     7626          324            2353.703704\n",
      "6    MP01                     7216          324            2227.160494\n",
      "7    RJ01                     9682          324            2988.271605\n",
      "8    TN01                     2551          324             787.345679\n",
      "9    UP01                     9597          324            2962.037037\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "trips_df = pd.read_csv(r\"C:\\Users\\anshi\\OneDrive\\Desktop\\Data analyst\\Resume project challange_13\\resources\\datasets\\csv_files\\trips_db\\fact_trips.csv\", parse_dates=[\"date\"],dayfirst=True)\n",
    "dim_date_df = pd.read_csv(r\"C:\\Users\\anshi\\OneDrive\\Desktop\\Data analyst\\Resume project challange_13\\resources\\datasets\\csv_files\\trips_db\\dim_date.csv\", parse_dates=[\"date\", \"start_of_month\"])\n",
    "dim_repeat_trip_distribution_df = pd.read_csv(r\"C:\\Users\\anshi\\OneDrive\\Desktop\\Data analyst\\Resume project challange_13\\resources\\datasets\\csv_files\\trips_db\\dim_repeat_trip_distribution.csv\", parse_dates=[\"month\"])\n",
    "\n",
    "# Convert 'date' columns to datetime (in case they're not already in the correct format)\n",
    "trips_df['date'] = pd.to_datetime(trips_df['date'], errors='coerce')\n",
    "dim_date_df['date'] = pd.to_datetime(dim_date_df['date'], errors='coerce')\n",
    "\n",
    "# Clean and preprocess the datasets\n",
    "# Remove \"-Trips\" suffix and convert `trip_count` to numeric\n",
    "dim_repeat_trip_distribution_df['trip_count'] = dim_repeat_trip_distribution_df['trip_count'].str.replace('-Trips', '').astype(int)\n",
    "\n",
    "# Ensure all numeric columns in fact_trips are properly formatted\n",
    "trips_df['distance_travelled(km)'] = pd.to_numeric(trips_df['distance_travelled(km)'], errors='coerce')\n",
    "trips_df['fare_amount'] = pd.to_numeric(trips_df['fare_amount'], errors='coerce')\n",
    "\n",
    "# Primary Analysis Functions\n",
    "\n",
    "# 1. Top and Bottom Performing Cities by Total Trips\n",
    "def top_bottom_cities(trips_df):\n",
    "    city_summary = trips_df.groupby('city_id').agg(\n",
    "        total_trips=('trip_id', 'count')\n",
    "    ).reset_index()\n",
    "    city_summary = city_summary.sort_values(by='total_trips', ascending=False)\n",
    "    top_cities = city_summary.head(3)\n",
    "    bottom_cities = city_summary.tail(3)\n",
    "    return top_cities, bottom_cities\n",
    "\n",
    "# 2. Average Fare per Trip by City\n",
    "def avg_fare_per_trip(trips_df):\n",
    "    avg_fare = trips_df.groupby('city_id').agg(\n",
    "        total_fare=('fare_amount', 'sum'),\n",
    "        total_trips=('trip_id', 'count')\n",
    "    ).reset_index()\n",
    "    avg_fare['avg_fare_per_trip'] = avg_fare['total_fare'] / avg_fare['total_trips']\n",
    "    return avg_fare[['city_id', 'avg_fare_per_trip']]\n",
    "\n",
    "# 3. Peak and Low Demand Months by City\n",
    "def peak_low_demand(trips_df, dim_date_df):\n",
    "    trips_df = pd.merge(trips_df, dim_date_df[['date', 'month_name']], on='date', how='left')\n",
    "    monthly_summary = trips_df.groupby(['city_id', 'month_name']).agg(\n",
    "        total_trips=('trip_id', 'count')\n",
    "    ).reset_index()\n",
    "    peak_months = monthly_summary.loc[monthly_summary.groupby('city_id')['total_trips'].idxmax()]\n",
    "    low_months = monthly_summary.loc[monthly_summary.groupby('city_id')['total_trips'].idxmin()]\n",
    "    return peak_months, low_months\n",
    "\n",
    "# 4. Weekend vs Weekday Trip Demand\n",
    "def weekend_vs_weekday_analysis(trips_df, dim_date_df):\n",
    "    trips_df = pd.merge(trips_df, dim_date_df[['date', 'day_type']], on='date', how='left')\n",
    "    weekday_weekend = trips_df.groupby(['city_id', 'day_type']).agg(\n",
    "        total_trips=('trip_id', 'count')\n",
    "    ).reset_index()\n",
    "    return weekday_weekend\n",
    "\n",
    "# 5. Repeat Passenger Frequency and Contribution\n",
    "def repeat_passenger_analysis(dim_repeat_trip_distribution_df):\n",
    "    repeat_freq = dim_repeat_trip_distribution_df.groupby(['city_id']).agg(\n",
    "        total_repeat_passengers=('repeat_passenger_count', 'sum'),\n",
    "        total_trips=('trip_count', 'sum')\n",
    "    ).reset_index()\n",
    "    repeat_freq['repeat_passenger_rate'] = (\n",
    "        repeat_freq['total_repeat_passengers'] * 100.0 / repeat_freq['total_trips']\n",
    "    )\n",
    "    return repeat_freq\n",
    "\n",
    "# Run the analysis\n",
    "analysis_results = {\n",
    "    \"top_bottom_cities\": top_bottom_cities(trips_df),\n",
    "    \"avg_fare_per_trip\": avg_fare_per_trip(trips_df),\n",
    "    \"peak_low_demand\": peak_low_demand(trips_df, dim_date_df),\n",
    "    \"weekend_vs_weekday\": weekend_vs_weekday_analysis(trips_df, dim_date_df),\n",
    "    \"repeat_passenger_analysis\": repeat_passenger_analysis(dim_repeat_trip_distribution_df)\n",
    "}\n",
    "\n",
    "# Print the results to the console\n",
    "for key, result in analysis_results.items():\n",
    "    if isinstance(result, tuple):  # Handle metrics with high/low segmentation\n",
    "        print(f\"\\n{key} - High:\\n\", result[0])\n",
    "        print(f\"\\n{key} - Low:\\n\", result[1])\n",
    "    else:\n",
    "        print(f\"\\n{key}:\\n\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d050e-ad30-4a3a-817f-dd2b2b060988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factors_influencing_repeat_passenger_rate(trips_df, repeat_passenger_data):\n",
    "    # Merge the repeat passenger data with the trips dataset\n",
    "    combined_data = pd.merge(trips_df, repeat_passenger_data, on='city_id', how='left')\n",
    "\n",
    "    # Calculate correlation between factors and repeat passenger rate\n",
    "    correlation_data = combined_data[['avg_fare_per_trip', 'total_trips', 'avg_passenger_rating', 'repeat_passenger_rate']].corr()\n",
    "\n",
    "    return correlation_data\n",
    "\n",
    "# Call the function\n",
    "repeat_factors_correlation = factors_influencing_repeat_passenger_rate(trips_df, repeat_passenger_analysis)\n",
    "print(repeat_factors_correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc25860-c855-48e7-9646-621571d0ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tourism_business_demand_impact(trips_df, tourism_cities):\n",
    "    # Filter trips data for tourism-focused cities\n",
    "    tourism_data = trips_df[trips_df['city_id'].isin(tourism_cities)]\n",
    "    \n",
    "    # Aggregate trips by month and city to observe seasonal trends\n",
    "    tourism_monthly_data = tourism_data.groupby(['city_id', 'month_name']).agg(\n",
    "        total_trips=('trip_id', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    # You can also add analysis of peak months for tourism cities\n",
    "    tourism_peak_months = tourism_monthly_data.loc[tourism_monthly_data.groupby('city_id')['total_trips'].idxmax()]\n",
    "\n",
    "    return tourism_monthly_data, tourism_peak_months\n",
    "\n",
    "# Example of tourism cities (should be provided based on actual categorization)\n",
    "tourism_cities = ['AP01', 'CH01', 'TN01']\n",
    "tourism_data, tourism_peak_months = tourism_business_demand_impact(trips_df, tourism_cities)\n",
    "\n",
    "# Print the results\n",
    "print(tourism_data)\n",
    "print(tourism_peak_months)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62886ec7-d617-4f1b-946c-51abf70f12ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_target_achievement(trips_df, target_trips_df):\n",
    "    # Merge the target data with actual trips data\n",
    "    merged_data = pd.merge(trips_df, target_trips_df[['city_id', 'month_name', 'total_target_trips']], on=['city_id', 'month_name'], how='left')\n",
    "    \n",
    "    # Calculate achievement percentage for each city and month\n",
    "    merged_data['trip_target_achievement'] = (merged_data['total_trips'] / merged_data['total_target_trips']) * 100\n",
    "    \n",
    "    # Identify if the target was met, exceeded, or missed\n",
    "    merged_data['target_status'] = merged_data['trip_target_achievement'].apply(lambda x: 'Exceeded' if x > 100 else ('Met' if x == 100 else 'Missed'))\n",
    "\n",
    "    return merged_data[['city_id', 'month_name', 'trip_target_achievement', 'target_status']]\n",
    "\n",
    "# Run the target achievement analysis\n",
    "target_achievement_data = monthly_target_achievement(trips_df, target_trips_df)\n",
    "\n",
    "# Print the results\n",
    "print(target_achievement_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c388fb0-19de-4b72-b15b-678f86141c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_passenger_rate_by_month(trips_df, dim_repeat_trip_distribution_df):\n",
    "    # Merge the repeat trip distribution data with trips\n",
    "    repeat_data = pd.merge(trips_df, dim_repeat_trip_distribution_df, on=['city_id', 'month'], how='left')\n",
    "    \n",
    "    # Calculate repeat passenger rate (RPR%) for each city and month\n",
    "    repeat_data['repeat_passenger_rate'] = (repeat_data['repeat_passenger_count'] / repeat_data['trip_count']) * 100\n",
    "    \n",
    "    # Identify the highest and lowest repeat passenger rates\n",
    "    highest_rpr = repeat_data.loc[repeat_data.groupby('city_id')['repeat_passenger_rate'].idxmax()]\n",
    "    lowest_rpr = repeat_data.loc[repeat_data.groupby('city_id')['repeat_passenger_rate'].idxmin()]\n",
    "\n",
    "    return highest_rpr[['city_id', 'month', 'repeat_passenger_rate']], lowest_rpr[['city_id', 'month', 'repeat_passenger_rate']]\n",
    "\n",
    "# Run the analysis\n",
    "highest_rpr, lowest_rpr = repeat_passenger_rate_by_month(trips_df, dim_repeat_trip_distribution_df)\n",
    "\n",
    "# Print the results\n",
    "print(\"Highest Repeat Passenger Rate (RPR%) by City and Month:\")\n",
    "print(highest_rpr)\n",
    "print(\"\\nLowest Repeat Passenger Rate (RPR%) by City and Month:\")\n",
    "print(lowest_rpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a1bc2-3867-4d55-92dd-6412dd38f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mobility_trends():\n",
    "    # Example function for analyzing emerging trends, such as electric vehicles\n",
    "    # We would need external data for electric vehicle adoption rates, and so on\n",
    "    pass  # Placeholder function for future data integration\n",
    "\n",
    "# This would need external data collection\n",
    "analyze_mobility_trends()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1001224a-bb64-4b6d-98bc-41f1ce0e234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partnership_opportunities():\n",
    "    # This would involve gathering foot traffic data and matching it with customer demand patterns\n",
    "    pass  # Placeholder function for further business analysis\n",
    "\n",
    "# Placeholder for partnership opportunities function\n",
    "partnership_opportunities()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc8488-7760-4f96-84c3-6694db4ef6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collection_recommendations():\n",
    "    # Suggest data collection methods for deeper insights\n",
    "    print(\"1. Collect customer satisfaction scores and analyze trends.\")\n",
    "    print(\"2. Track operational efficiency metrics: average wait times, driver ratings.\")\n",
    "    print(\"3. Monitor market trends: competitor pricing, customer preferences.\")\n",
    "    \n",
    "# Print the data collection recommendations\n",
    "data_collection_recommendations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5a63d-ddc8-4d65-98b7-f8075673a105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
